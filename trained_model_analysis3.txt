Analyzing trained model: examples/navigation/logs/level1/level1_18_iteration_17000.pth
============================================================
Trained DepthNav Model Analysis
============================================================
Model path: examples/navigation/logs/level1/level1_18_iteration_17000.pth

Loading model checkpoint...
Checkpoint loaded successfully!
Checkpoint keys: ['policy_net.0.weight', 'policy_net.0.bias', 'feature_extractor.depth_extractor.0.weight', 'feature_extractor.depth_extractor.0.bias', 'feature_extractor.depth_extractor.2.weight', 'feature_extractor.depth_extractor.2.bias', 'feature_extractor.depth_extractor.4.weight', 'feature_extractor.depth_extractor.4.bias', 'feature_extractor.depth_extractor.mlp.0.weight', 'feature_extractor.depth_extractor.mlp.0.bias', 'feature_extractor.depth_extractor.mlp.1.weight', 'feature_extractor.depth_extractor.mlp.1.bias', 'feature_extractor.state_extractor.0.weight', 'feature_extractor.state_extractor.0.bias', 'feature_extractor.state_extractor.1.weight', 'feature_extractor.state_extractor.1.bias', 'feature_extractor.target_extractor.0.weight', 'feature_extractor.target_extractor.0.bias', 'feature_extractor.target_extractor.1.weight', 'feature_extractor.target_extractor.1.bias', 'feature_norm.weight', 'feature_norm.bias', 'recurrent_extractor.weight_ih', 'recurrent_extractor.weight_hh', 'recurrent_extractor.bias_ih', 'recurrent_extractor.bias_hh']
Using checkpoint directly as state_dict
State dict keys count: 26
Sample keys: ['policy_net.0.weight', 'policy_net.0.bias', 'feature_extractor.depth_extractor.0.weight', 'feature_extractor.depth_extractor.0.bias', 'feature_extractor.depth_extractor.2.weight']

Creating model architecture...
Model created successfully!
Model type: <class 'depthnav.policies.multi_input_policy.MultiInputPolicy'>
Total trainable parameters (before loading): 2,220,644
Error loading model weights: Error(s) in loading state_dict for MultiInputPolicy:
	size mismatch for feature_extractor.depth_extractor.0.weight: copying a param with shape torch.Size([32, 1, 2, 2]) from checkpoint, the shape in current model is torch.Size([32, 64, 2, 2]).
	size mismatch for feature_extractor.state_extractor.0.weight: copying a param with shape torch.Size([192, 7]) from checkpoint, the shape in current model is torch.Size([192, 10]).
	size mismatch for feature_extractor.target_extractor.0.weight: copying a param with shape torch.Size([192, 4]) from checkpoint, the shape in current model is torch.Size([192, 3]).
Continuing with the model architecture analysis...
Total trainable parameters (after loading): 2,220,644

Sample input created:
  state: torch.Size([1, 10])
  target: torch.Size([1, 3])
  depth: torch.Size([1, 64, 64, 2])

Calculating FLOPs using thop...
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.
[INFO] Register count_relu() for <class 'torch.nn.modules.activation.LeakyReLU'>.
[INFO] Register count_normalization() for <class 'torch.nn.modules.normalization.LayerNorm'>.
[INFO] Register count_gru_cell() for <class 'torch.nn.modules.rnn.GRUCell'>.
FLOPs (using thop): 11,307,648
Parameters (using thop): 2,220,644.0

============================================================
Parameter Breakdown by Module
============================================================
policy_net               :             772 parameters (  0.03%)
feature_extractor        :       1,997,152 parameters ( 89.94%)
feature_norm             :             384 parameters (  0.02%)
recurrent_extractor      :         222,336 parameters ( 10.01%)

============================================================
Additional Model Information
============================================================
Feature extractor output dimension: 192
Recurrent layer hidden size: 192

Model analysis completed successfully!
